---
title: "CS109b Final Project Milestone 3"
author: "Phillip Huang"
date: "4/19/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("caTools")
library("utiml")
# library("randomForest")
```


```{r}
imdb5k <- read.csv('imdb5konehot.csv')
# msk <- sample.split(imdb5k, SplitRatio=8/10)
# train <- imdb5k[msk,]
# test <- imdb5k[!msk,]
#     
# startsWith(colnames(imdb5k), "i_")
which(startsWith(colnames(imdb5k), "i_"))
```

```{r}
imdb5k.clean <- imdb5k[!apply(imdb5k, 1, function(x) any(is.na(x))),]
```


```{r}
imdb5k.mldr <- mldr_from_dataframe(dataframe=imdb5k.clean, labelIndices=which(startsWith(colnames(imdb5k), "i_")))
```


```{r}
# Create two partitions (train and test) of toyml multi-label dataset
ds <- create_holdout_partition(imdb5k.mldr, c(train=0.65, test=0.35))

# Create a Binary Relevance Model using e1071::svm method
brmodel <- br(ds$train, "SVM", seed=123)

# Predict
prediction <- predict(brmodel, ds$test)

# Show the predictions
head(as.bipartition(prediction))
head(as.ranking(prediction))

# Apply a threshold
newpred <- rcut_threshold(prediction, 2)

# Evaluate the models
result <- multilabel_evaluate(ds$tes, prediction, "bipartition")
thresres <- multilabel_evaluate(ds$tes, newpred, "bipartition")

# Print the result
print(round(cbind(Default=result, RCUT=thresres), 3))
```

```{r}
# Create three partitions (train, val, test) of emotions dataset
partitions <- c(train = 0.6, val = 0.2, test = 0.2)
ds <- create_holdout_partition(imdb5k.mldr, partitions, method="iterative")

# Create an Ensemble of Classifier Chains using Random Forest (randomForest package)
eccmodel <- ecc(ds$train, "RF", m=3, cores=parallel::detectCores(), seed=123)

# Predict
val <- predict(eccmodel, ds$val, cores=parallel::detectCores())
test <- predict(eccmodel, ds$test, cores=parallel::detectCores())

# Apply a threshold
thresholds <- scut_threshold(val, ds$val, cores=parallel::detectCores())
new.val <- fixed_threshold(val, thresholds)
new.test <- fixed_threshold(test, thresholds)

# Evaluate the models
measures <- c("subset-accuracy", "F1", "hamming-loss", "macro-based") 

result <- cbind(
  Test = multilabel_evaluate(ds$tes, test, measures),
  TestWithThreshold = multilabel_evaluate(ds$tes, new.test, measures),
  Validation = multilabel_evaluate(ds$val, val, measures),
  ValidationWithThreshold = multilabel_evaluate(ds$val, new.val, measures)
)

print(round(result, 3))
```

